import os
import discord
from discord.ext import commands
from huggingface_hub import InferenceClient
from io import BytesIO

# Client HuggingFace
client_hf = InferenceClient(
    token=os.getenv("HF_TOKEN")  # Assure-toi que ton .env contient HF_TOKEN
)

class ImageGen(commands.Cog):
    def __init__(self, bot):
        self.bot = bot

    @commands.command(name="img", help="G√©n√®re une image √† partir d'un prompt texte")
    async def img(self, ctx: commands.Context, *, prompt: str):
        """Commande classique (pr√©fixe uniquement) pour g√©n√©rer une image"""
        try:
            # G√©n√©ration de l'image (renvoie d√©j√† un PIL.Image)
            image = client_hf.text_to_image(
                prompt,
                model="stabilityai/stable-diffusion-xl-base-1.0"
            )

            # Conversion en bytes pour Discord
            img_bytes = BytesIO()
            image.save(img_bytes, format="PNG")
            img_bytes.seek(0)
            file = discord.File(img_bytes, filename="image.png")

            # Embed
            embed = discord.Embed(
                title="üñºÔ∏è Image g√©n√©r√©e",
                description=f"Prompt : `{prompt}`",
                color=discord.Color.blue()
            )
            embed.set_image(url="attachment://image.png")

            await ctx.send(embed=embed, file=file)

        except Exception as e:
            await ctx.send(f"‚ùå Erreur lors de la g√©n√©ration de l'image : {e}")

async def setup(bot):
    await bot.add_cog(ImageGen(bot))
